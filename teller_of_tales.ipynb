{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YQYYCwGbrCJrvpQ6rnbfsNf64yI34Zf9",
      "authorship_tag": "ABX9TyPGp3B8fflPPbkEv79lOGVX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dawmro/teller_of_tales/blob/main/teller_of_tales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install an import openai\n",
        "!pip install openai==0.26.4\n",
        "import openai"
      ],
      "metadata": {
        "id": "kvcB828HnmgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use API_KEY for ChatGPT\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# show step by step debug info?\n",
        "DEBUG = True\n",
        "\n",
        "# minimal amount of words to put in each story fragment\n",
        "FRAGMENT_LENGTH = 10\n",
        "\n",
        "# select model to use\n",
        "model_engine = \"text-davinci-003\"\n",
        "\n",
        "# set image width and height\n",
        "# image_width = 1024\n",
        "# image_height = 576 \n",
        "image_width = 1360\n",
        "image_height = 768"
      ],
      "metadata": {
        "id": "xr1i36cYg32s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# login to hugginface using your token https://huggingface.co/settings/tokens\n",
        "!pip install huggingface-hub\n",
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "XgLDXQzZhPms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paste your story below %%writefile story.txt line\n",
        "%%writefile story.txt\n"
      ],
      "metadata": {
        "id": "yEh9fmXXuo92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmed to work on Python 3.8.10 \n",
        "!python -V"
      ],
      "metadata": {
        "id": "56deiTl6eLVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "TgxuPWbCVEzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install nltk\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "mYORn5UygXri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "w5RmJOOQhqDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for time\n",
        "from datetime import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "z2HTPw2JnhoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import fnmatch\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "VFVHW-IJn7a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.11.1\n",
        "!pip install transformers scipy ftfy accelerate"
      ],
      "metadata": {
        "id": "ks-fu_XPjsgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import DPMSolverMultistepScheduler"
      ],
      "metadata": {
        "id": "qjeZwvKrkQRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS==2.3.1\n",
        "from gtts import gTTS"
      ],
      "metadata": {
        "id": "TwEOf8ggodf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install imagemagick\n",
        "!sed -i '/<policy domain=\"path\" rights=\"none\" pattern=\"@\\*\"/d' /etc/ImageMagick-6/policy.xml"
      ],
      "metadata": {
        "id": "EF3AX-lV0Qw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy==1.0.3\n",
        "!pip install imageio-ffmpeg==0.4.8\n",
        "from moviepy.editor import *"
      ],
      "metadata": {
        "id": "Vvg2At3ZpEA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createFolders():\n",
        "    if not os.path.exists(\"text\"):\n",
        "        print(\"Creating text directory...\")\n",
        "        os.makedirs(\"text\") \n",
        "    if not os.path.exists(\"text/story_sentences\"):\n",
        "        print(\"Creating text/story_sentences directory...\")\n",
        "        os.makedirs(\"text/story_sentences\") \n",
        "    if not os.path.exists(\"text/story_fragments\"):\n",
        "        print(\"Creating text/story_fragments directory...\")\n",
        "        os.makedirs(\"text/story_fragments\") \n",
        "    if not os.path.exists(\"text/image_prompts\"):\n",
        "        print(\"Creating text/image_prompts directory...\")\n",
        "        os.makedirs(\"text/image_prompts\") \n",
        "    if not os.path.exists(\"audio\"):\n",
        "        print(\"Creating audio directory...\")\n",
        "        os.makedirs(\"audio\")         \n",
        "    if not os.path.exists(\"images\"):\n",
        "        print(\"Creating images directory...\")\n",
        "        os.makedirs(\"images\")     \n",
        "    if not os.path.exists(\"videos\"):\n",
        "        print(\"Creating videos directory...\")\n",
        "        os.makedirs(\"videos\")"
      ],
      "metadata": {
        "id": "SbxYVNZmrWtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_list(a_list, filename):\n",
        "    print(\"Started writing list data into a json file\")\n",
        "    with open(filename, \"w\") as fp:\n",
        "        json.dump(a_list, fp)\n",
        "        print(\"Done writing JSON data into .json file\")\n",
        "\n",
        "\n",
        "def read_list(filename):\n",
        "    # for reading also binary mode is important\n",
        "    with open(filename, 'rb') as fp:\n",
        "        n_list = json.load(fp)\n",
        "        return n_list\n",
        "        \n",
        "                \n",
        "def write_file(file_content, filename):\n",
        "    print(\"Started writing file_content data into a file\")\n",
        "    with open(filename, \"w\") as fp:\n",
        "        fp.write(file_content)\n",
        "        print(\"Done file_content data into a file\")\n",
        "        \n",
        "        \n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as fp:\n",
        "        file_content = fp.read()\n",
        "        return file_content"
      ],
      "metadata": {
        "id": "T37LLTcqrdhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def showTime():\n",
        "    return str(\"[\"+datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')+\" UTC]\")\n",
        "\n",
        "\n",
        "def pause():\n",
        "    programPause = input(\"Press the <ENTER> key to continue...\")"
      ],
      "metadata": {
        "id": "aBJoGZ-5rq1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_split_to_sentences(filename):\n",
        "\n",
        "    # read raw story from txt file\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "        story_raw = file.read()\n",
        "\n",
        "    # remove quotes from story\n",
        "    story = story_raw.replace('“', '').replace('”', '').replace('——', ' ')\n",
        "\n",
        "    # split story into list of sentences\n",
        "    story_sentences_list = sent_tokenize(story)\n",
        "    \n",
        "    # write_list(story_sentences_list, \"text/story_sentences_list.json\")\n",
        "    \n",
        "    for i, story_sentence in enumerate(story_sentences_list):\n",
        "        write_file(story_sentence, f\"text/story_sentences/story_sentence{i}.txt\")\n",
        "    \n",
        "    if DEBUG:\n",
        "        # display story enumerating through each sentence\n",
        "        for i, story_sentence in enumerate(story_sentences_list):\n",
        "            print( i, story_sentence)\n",
        "        print(\"\\n!!!!!!!!!!!!!!\\nThis is last chance to make changes in story_sentences.txt files\\n!!!!!!!!!!!!!!\")\n",
        "        pause()\n",
        "    \n",
        "    dir_path = r'text/story_sentences'\n",
        "    number_of_files = len(fnmatch.filter(os.listdir(dir_path), 'story_sentence*.txt'))\n",
        "    print('number_of_files:', number_of_files)\n",
        "    \n",
        "    return number_of_files"
      ],
      "metadata": {
        "id": "AHJq-pa3ru_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentences_to_fragments(number_of_story_sentences, FRAGMENT_LENGTH):\n",
        "\n",
        "    # story divided into fragments\n",
        "    story_fragments = []\n",
        "\n",
        "    # fragment currently being worked on\n",
        "    current_fragment = None\n",
        "\n",
        "    # current fragment word counter\n",
        "    current_fragment_word_counter = 0\n",
        "\n",
        "    # for every sentence in list of sentences\n",
        "    # combine sentences form story into fragments\n",
        "    for i in range(number_of_story_sentences):\n",
        "        \n",
        "        # load current sentence\n",
        "        story_sentence = read_file(f\"text/story_sentences/story_sentence{i}.txt\")\n",
        "        \n",
        "        # insert story sentence if current fragment is empty\n",
        "        if current_fragment == None:\n",
        "            current_fragment = story_sentence   \n",
        "            \n",
        "        # add story sentence to current fragment    \n",
        "        else:\n",
        "            current_fragment += ' ' + story_sentence\n",
        "            \n",
        "        # get amount of words in fragment    \n",
        "        current_fragment_word_counter = len(word_tokenize(current_fragment))\n",
        "        \n",
        "        # if minimal length requirement is meet\n",
        "        if current_fragment_word_counter > FRAGMENT_LENGTH:\n",
        "            if DEBUG:\n",
        "                print(current_fragment_word_counter)\n",
        "        \n",
        "            # add current fragment to story fragments\n",
        "            story_fragments.append(current_fragment)\n",
        "            \n",
        "            # zero temporary variables\n",
        "            current_fragment = None\n",
        "            current_fragment_word_counter = 0\n",
        "     \n",
        "    # add last fragment \n",
        "    if current_fragment is not None:\n",
        "        story_fragments.append(current_fragment)\n",
        "    \n",
        "    # write_list(story_fragments, \"text/story_fragments.json\")\n",
        "    \n",
        "    for i, story_fragment in enumerate(story_fragments):\n",
        "        write_file(story_fragment, f\"text/story_fragments/story_fragment{i}.txt\")\n",
        "    \n",
        "    if DEBUG:\n",
        "        # display story enumerating through each sentence\n",
        "        for i, story_fragment in enumerate(story_fragments):\n",
        "            print( i, story_fragment)\n",
        "        print(\"\\n!!!!!!!!!!!!!!\\nThis is last chance to make changes in story_fragments.txt files\\n!!!!!!!!!!!!!!\")\n",
        "        pause()\n",
        "        \n",
        "    dir_path = r'text/story_fragments'\n",
        "    number_of_files = len(fnmatch.filter(os.listdir(dir_path), 'story_fragment*.txt'))\n",
        "    print('number_of_files:', number_of_files)\n",
        "    \n",
        "    return number_of_files"
      ],
      "metadata": {
        "id": "CH5NA7tmr0YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_to_image(i, image_width, image_height):\n",
        "\n",
        "    image_prompt = read_file(f\"text/image_prompts/image_prompt{i}.txt\")\n",
        "    # clear cuda cache\n",
        "    with torch.no_grad():\n",
        "        torch.cuda.empty_cache() \n",
        "    \n",
        "    # set parameters for image \n",
        "    seed = 1337\n",
        "\n",
        "    possitive_prompt_sufix = \" (extremely detailed CG unity 8k wallpaper), nostalgia, professional majestic oil painting, trending on ArtStation, trending on CGSociety, Intricate, High Detail, Sharp focus, dramatic, by midjourney and greg rutkowski, realism, beautiful and detailed lighting, shadows, by Jeremy Lipking\"\n",
        "\n",
        "    negative_prompt = \"disfigured, kitsch, ugly, oversaturated, grain, low-res, Deformed, blurry, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, ugly, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, ugly, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal, text\"\n",
        "    \n",
        "    model_id = \"darkstorm2150/Protogen_v2.2_Official_Release\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "    \n",
        "    # consider chunking the attention computation if limited by GPU memory \n",
        "    pipe.enable_attention_slicing()\n",
        "    \n",
        "    prompt = image_prompt + possitive_prompt_sufix\n",
        "        \n",
        "    image = pipe(prompt=prompt, negative_prompt=negative_prompt, height=image_height, width=image_width, guidance_scale=7.5, generator=generator, num_inference_steps=25).images[0]\n",
        "\n",
        "    image.save(f\"images/image{i}.jpg\")"
      ],
      "metadata": {
        "id": "DPEWpc_Gr6Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createVideoClip(i):\n",
        "\n",
        "    story_fragment = read_file(f\"text/story_fragments/story_fragment{i}.txt\")\n",
        "    \n",
        "    # create gTTS instance and save to a file\n",
        "    tts = gTTS(text=story_fragment, lang='en', slow=False)\n",
        "    tts.save(f\"audio/voiceover{i}.mp3\")\n",
        "    \n",
        "    # load the audio file using moviepy\n",
        "    audio_clip = AudioFileClip(f\"audio/voiceover{i}.mp3\")\n",
        "    audio_duration = audio_clip.duration\n",
        "    \n",
        "    # audio creation using coqui-ai/TTS\n",
        "    '''\n",
        "    # create coqui-ai/TTS instance and save to a file\n",
        "    outputs = syn.tts(story_fragment.replace('\\n', ' '))\n",
        "    syn.save_wav(outputs, f\"audio/voiceover{i}.mp3\")\n",
        "    \n",
        "    # load the audio file using moviepy\n",
        "    audio_clip = AudioFileClip(f\"audio/voiceover{i}.mp3\")\n",
        "    audio_duration = audio_clip.duration\n",
        "    '''\n",
        "    \n",
        "    # load the image file using moviepy\n",
        "    image_clip = ImageClip(f\"images/image{i}.jpg\").set_duration(audio_duration)\n",
        "    \n",
        "    # use moviepy to create a text clip from the text\n",
        "    screensize = (image_width, image_height)\n",
        "    text_clip = TextClip(story_fragment, fontsize=40, font=\"Helvetica-Bold\", color=\"black\", stroke_color=\"white\", stroke_width=1.5, size=screensize, method='caption', align=\"South\")\n",
        "    text_clip = text_clip.set_duration(audio_duration)\n",
        "    \n",
        "    # concatenate the audio, image, and text clips\n",
        "    clip = image_clip.set_audio(audio_clip)\n",
        "    video = CompositeVideoClip([clip, text_clip])\n",
        "    \n",
        "    # save Video Clip to a file\n",
        "    video = video.write_videofile(f\"videos/video{i}.mp4\", fps=24)\n",
        "    print(f\"{showTime()} The Video{i} Has Been Created Successfully!\")"
      ],
      "metadata": {
        "id": "0t0vZF53sDtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def askChatGPT(text, model_engine):\n",
        "    do_it = True\n",
        "    answer = ''\n",
        "    while(do_it):\n",
        "        try: \n",
        "            completions = openai.Completion.create(\n",
        "                engine=model_engine,\n",
        "                prompt=text,\n",
        "                max_tokens=100,\n",
        "                n=1,\n",
        "                stop=None,\n",
        "                temperature=0.9,\n",
        "            )\n",
        "            do_it = False\n",
        "            answer = completions.choices[0].text\n",
        "        except:\n",
        "            print(\"Exception!!! Waiting for 60 seconds and trying again...\")\n",
        "            time.sleep(60)\n",
        "            answer = askChatGPT(text, model_engine)\n",
        "    \n",
        "    return answer   "
      ],
      "metadata": {
        "id": "TJgQqBoRsK9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createListOfClips():\n",
        "\n",
        "    clips = []\n",
        "    l_files = os.listdir(\"videos\")\n",
        "    l_files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "    for file in l_files:\n",
        "        clip = VideoFileClip(f\"videos/{file}\")\n",
        "        clips.append(clip)\n",
        "    \n",
        "    return clips"
      ],
      "metadata": {
        "id": "YNuZJU0WsNwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main loop\n",
        "\n",
        "print(f\"{showTime()}\")\n",
        "\n",
        "if DEBUG:\n",
        "    pause()\n",
        "    \n",
        "# Create directiories for text, audio, images and video files    \n",
        "createFolders()\n",
        "\n",
        "# load story and split it by sentence\n",
        "number_of_story_sentences = load_and_split_to_sentences(\"story.txt\")\n",
        "\n",
        "# group sentences into story fragments of a given length\n",
        "number_of_story_fragments = sentences_to_fragments(number_of_story_sentences, FRAGMENT_LENGTH)\n",
        "\n",
        "image_prompts = []\n",
        "    \n",
        "# for each story fragment\n",
        "for i in range(number_of_story_fragments):\n",
        "    print(f\"{showTime()}\")\n",
        "    \n",
        "    if(Path(f\"text/image_prompts/image_prompt{i}.txt\").is_file() == False):\n",
        "        story_fragment = read_file(f\"text/story_fragments/story_fragment{i}.txt\")\n",
        "        prefix = \"Suggest good image to illustrate the following fragment from story, make descrpition short and precise, one sentence, max 10 words: \"\n",
        "        # translate fragment into prompt\n",
        "        image_prompt = askChatGPT(prefix + story_fragment, model_engine).strip()\n",
        "        print(i, story_fragment)\n",
        "        print(i, image_prompt)\n",
        "        write_file(image_prompt, f\"text/image_prompts/image_prompt{i}.txt\") \n",
        "    \n",
        "    if(Path(f\"images/image{i}.jpg\").is_file() == False):\n",
        "        # generate image form prompt \n",
        "        prompt_to_image(i, image_width, image_height)\n",
        "    \n",
        "    if(Path(f\"videos/video{i}.mp4\").is_file() == False):\n",
        "        # create video clip using story fragment and generated image\n",
        "        createVideoClip(i)\n",
        "    \n",
        "    # if DEBUG:\n",
        "        # pause()\n",
        "\n",
        "# create sorted list of clips\n",
        "print(f\"{showTime()} Fixing order of video clips\")\n",
        "clips = createListOfClips()\n",
        "\n",
        "# add audio fade to prevent audio glitches when combining multiple clips\n",
        "clips = [clip.audio_fadein(0.05).audio_fadeout(0.05) for clip in clips]\n",
        "\n",
        "# combine all clips into final video\n",
        "print(f\"{showTime()} Concatenate all clips into final video...\")\n",
        "final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "final_video = final_video.write_videofile(\"final_video.mp4\")\n",
        "print(f\"{showTime()} Final video created successfully!\")"
      ],
      "metadata": {
        "id": "ga8sFjCbsR_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}